{
    "nbformat": 4, 
    "metadata": {
        "language_info": {
            "pygments_lexer": "ipython2", 
            "file_extension": ".py", 
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "codemirror_mode": {
                "name": "ipython", 
                "version": 2
            }, 
            "version": "2.7.11", 
            "name": "python"
        }, 
        "kernelspec": {
            "name": "python2-spark21", 
            "language": "python", 
            "display_name": "Python 2 with Spark 2.1"
        }
    }, 
    "cells": [
        {
            "outputs": [], 
            "source": "#!wget https://raw.githubusercontent.com/romeokienzler/developerWorks/master/model.h5\n#!wget https://raw.githubusercontent.com/romeokienzler/developerWorks/master/model.json", 
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}
        }, 
        {
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "--2017-12-12 15:14:03--  https://raw.githubusercontent.com/romeokienzler/developerWorks/master/watsoniotp.healthy.phase_aligned.pickle\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 194639 (190K) [text/plain]\nSaving to: \u2018watsoniotp.healthy.phase_aligned.pickle\u2019\n\n100%[======================================>] 194,639     --.-K/s   in 0.009s  \n\n2017-12-12 15:14:03 (21.3 MB/s) - \u2018watsoniotp.healthy.phase_aligned.pickle\u2019 saved [194639/194639]\n\n--2017-12-12 15:14:03--  https://raw.githubusercontent.com/romeokienzler/developerWorks/master/watsoniotp.broken.phase_aligned.pickle\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 185401 (181K) [text/plain]\nSaving to: \u2018watsoniotp.broken.phase_aligned.pickle\u2019\n\n100%[======================================>] 185,401     --.-K/s   in 0.01s   \n\n2017-12-12 15:14:03 (18.5 MB/s) - \u2018watsoniotp.broken.phase_aligned.pickle\u2019 saved [185401/185401]\n\n"
                }
            ], 
            "source": "!rm watsoniotp.*\n!wget https://raw.githubusercontent.com/romeokienzler/developerWorks/master/watsoniotp.healthy.phase_aligned.pickle\n!wget https://raw.githubusercontent.com/romeokienzler/developerWorks/master/watsoniotp.broken.phase_aligned.pickle", 
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}
        }, 
        {
            "outputs": [
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "Using TensorFlow backend.\n"
                }
            ], 
            "source": "import numpy as np\nfrom numpy import concatenate\nfrom matplotlib import pyplot\nfrom pandas import read_csv\nfrom pandas import DataFrame\nfrom pandas import concat\nimport sklearn\nfrom  sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.callbacks import Callback\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Activation\nfrom keras.models import model_from_json\nimport pickle\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport ibmiotf.application\nimport time\nfrom Queue import Queue\nimport numpy as np\nimport sys\n%matplotlib inline", 
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}
        }, 
        {
            "outputs": [], 
            "source": "def scaleData(data):\n    # normalize features\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    return scaler.fit_transform(data)", 
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}
        }, 
        {
            "outputs": [], 
            "source": "timesteps = 10\ndim = 3\nsamples = 3000", 
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}
        }, 
        {
            "outputs": [], 
            "source": "losses = []\n\ndef handleLoss(loss):\n        global losses\n        losses+=[loss]\n        print loss", 
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}
        }, 
        {
            "outputs": [], 
            "source": "class LossHistory(Callback):\n    def on_train_begin(self, logs={}):\n        self.losses = []\n\n    def on_batch_end(self, batch, logs={}):\n        self.losses.append(logs.get('loss'))\n        handleLoss(logs.get('loss'))", 
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}
        }, 
        {
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": "Loaded model from disk\n"
                }
            ], 
            "source": "# design network\nmodel = None\n\ndef reloadModel():\n    global model\n    json_file = open('model.json', 'r')\n    loaded_model_json = json_file.read()\n    json_file.close()\n    model = model_from_json(loaded_model_json)\n    # load weights into new model\n    model.load_weights(\"model.h5\")\n    print(\"Loaded model from disk\")\n    model.compile(loss='mae', optimizer='adam')\n\nreloadModel()\n\ndef train(data):\n    data.shape = (300, 10, 3)\n    model.fit(data, data, epochs=5, batch_size=72, validation_data=(data, data), verbose=0, shuffle=False,callbacks=[LossHistory()])\n    data.shape = (3000, 3)\n\ndef score(data):\n    data.shape = (300, 10, 3)\n    yhat =  model.predict(data)\n    yhat.shape = (3000, 3)\n    return yhat", 
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}
        }, 
        {
            "outputs": [
                {
                    "name": "stderr", 
                    "output_type": "stream", 
                    "text": "2017-12-12 15:14:22,642   ibmiotf.application.Client  INFO    Connected successfully: a:vpypwh:systemml\n"
                }
            ], 
            "source": "# USA options = {\"org\": \"oqyrc5\", \"id\": \"anything\", \"auth-method\": \"apikey\", \"auth-key\": \"a-oqyrc5-gqjx6gmrpc\", \"auth-token\": \"XZmvYr0i7-@JoJotiB\"}\n# GER options = {\"org\": \"vpypwh\", \"id\": \"systemml\", \"auth-method\": \"apikey\", \"auth-key\": \"a-vpypwh-uo4xdahvcy\", \"auth-token\": \"BwEwDnKSzHEgr?IcEc\"}\noptions = {\"org\": \"vpypwh\", \"id\": \"systemml\", \"auth-method\": \"apikey\", \"auth-key\": \"a-vpypwh-uo4xdahvcy\", \"auth-token\": \"BwEwDnKSzHEgr?IcEc\"}\nclient = ibmiotf.application.Client(options)\nclient.connect()", 
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {}
        }, 
        {
            "outputs": [], 
            "source": "q = Queue(7000)\nsimulator_status = 'disablesimulator'", 
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}
        }, 
        {
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "execution_count": 11, 
                    "data": {
                        "text/plain": "True"
                    }, 
                    "metadata": {}
                }
            ], 
            "source": "def myEventCallback(event):\n    global simulator_status\n    if event.event == 'switch':\n        simulator_status = event.data[\"message\"]\n        client.publishEvent(\"0.16.2\", \"lorenz\", \"switch_confirm\", \"json\", simulator_status)\n    if event.event == 'osc':\n        sample = event.data\n        point = [sample[\"x\"], sample[\"y\"],sample[\"z\"]]\n        q.put(point)\n\nclient.deviceEventCallback = myEventCallback\nclient.subscribeToDeviceEvents(\"0.16.2\", \"lorenz\", \"switch\")\nclient.subscribeToDeviceEvents(\"0.16.2\", \"lorenz\", \"osc\")\nclient.publishEvent(\"0.16.2\", \"lorenz\", \"alert\", \"json\", {'message' : 'no alert'})", 
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}
        }, 
        {
            "outputs": [], 
            "source": "def doNN(data):\n    data_scaled = scaleData(data)\n    train(data_scaled)\n    yhat = score(data_scaled)\n    data_scaled.shape = (3000, 3)", 
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}
        }, 
        {
            "outputs": [], 
            "source": "do_reset = False\nreset_start = 0\n\ndef handleLoss(loss):\n    global do_reset\n    global reset_start\n    sys.stdout.write('*')\n    sys.stdout.flush()\n    myData={'loss' : str(loss)}\n    client.publishEvent(\"0.16.2\", \"lorenz\", \"status\", \"json\", myData)\n    if loss > 0.08:\n        print \"loss > 0.08\"\n        do_reset = True\n        reset_start = int(time.time())\n        client.publishEvent(\"0.16.2\", \"lorenz\", \"alert\", \"json\", {'message' : 'alert'})\n    if do_reset:\n        if reset_start + 30 < int(time.time()):\n            print \"resetting\"\n            client.publishEvent(\"0.16.2\", \"lorenz\", \"alert\", \"json\", {'message' : 'no alert'})\n            client.publishEvent(\"0.16.2\", \"lorenz\", \"cmd\", \"json\", {'message' : 'stop'})\n            reloadModel()\n            do_reset = False\n            reset_start = 0\n        ", 
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}
        }, 
        {
            "outputs": [
                {
                    "name": "stdout", 
                    "output_type": "stream", 
                    "text": ".....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................Sending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*loss > 0.08\n*loss > 0.08\n*loss > 0.08\n*loss > 0.08\n*loss > 0.08\n*loss > 0.08\n*loss > 0.08\n*loss > 0.08\n*loss > 0.08\n****************Training finished......\nSending window downstream to the neural network...\n*************************Training finished......\nSending window downstream to the neural network...\n**loss > 0.08\n***********************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************resetting\nLoaded model from disk\n************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*loss > 0.08\n*loss > 0.08\n*loss > 0.08\n*loss > 0.08\n*loss > 0.08\n*loss > 0.08\n*loss > 0.08\n*loss > 0.08\n*loss > 0.08\n**loss > 0.08\n**************Training finished......\nSending window downstream to the neural network...\n*************************Training finished......\nSending window downstream to the neural network...\n**loss > 0.08\n***********************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n**************resetting\nLoaded model from disk\n***********Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n*************************Training finished...\nSending window downstream to the neural network...\n********************"
                }
            ], 
            "source": "while True:\n    while not q.empty() and simulator_status=='disablesimulator':\n        if simulator_status == 'disablesimulator':\n            sys.stdout.write('.')\n            sys.stdout.flush()\n            point = q.get()\n            try:\n                data\n            except NameError:\n                data = np.array(point)\n            else:\n                data = np.append(data,point)\n            if data.size>=9000:\n                data = np.reshape(data,(3000,3))\n                print \"Sending window downstream to the neural network...\"\n                doNN(data)\n                print \"Training finished...\"\n                del data\n    if simulator_status == 'simulatehealthy':\n        data_healthy = pickle.load(open('watsoniotp.healthy.phase_aligned.pickle', 'rb'))\n        data_healthy = data_healthy.reshape(3000,3)\n        print \"Sending window downstream to the neural network...\"\n        doNN(data_healthy)\n        print \"Training finished...\"\n    if simulator_status == 'simulatebroken':\n        data_broken = pickle.load(open('watsoniotp.broken.phase_aligned.pickle', 'rb'))\n        data_broken = data_broken.reshape(3000,3)\n        print \"Sending window downstream to the neural network...\"\n        doNN(data_broken)\n        print \"Training finished......\"\n            \n", 
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}
        }, 
        {
            "outputs": [], 
            "source": "", 
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}
        }
    ], 
    "nbformat_minor": 1
}