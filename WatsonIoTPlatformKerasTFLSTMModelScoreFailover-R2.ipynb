{
    "nbformat_minor": 1, 
    "cells": [
        {
            "metadata": {}, 
            "source": "#!wget https://raw.githubusercontent.com/romeokienzler/developerWorks/master/model.h5\n#!wget https://raw.githubusercontent.com/romeokienzler/developerWorks/master/model.json", 
            "execution_count": 1, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "#!rm watsoniotp.*\n#!wget https://raw.githubusercontent.com/romeokienzler/developerWorks/master/watsoniotp.healthy.phase_aligned.pickle\n#!wget https://raw.githubusercontent.com/romeokienzler/developerWorks/master/watsoniotp.broken.phase_aligned.pickle", 
            "execution_count": 2, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "import numpy as np\nfrom numpy import concatenate\nfrom matplotlib import pyplot\nfrom pandas import read_csv\nfrom pandas import DataFrame\nfrom pandas import concat\nimport sklearn\nfrom  sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.callbacks import Callback\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Activation\nfrom keras.models import model_from_json\nimport pickle\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport ibmiotf.application\nimport time\nfrom Queue import Queue\nimport numpy as np\nimport sys\n%matplotlib inline", 
            "execution_count": 3, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stderr", 
                    "text": "Using TensorFlow backend.\n", 
                    "output_type": "stream"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "def scaleData(data):\n    # normalize features\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    return scaler.fit_transform(data)", 
            "execution_count": 4, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "timesteps = 10\ndim = 3\nsamples = 3000", 
            "execution_count": 5, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "losses = []\n\ndef handleLoss(loss):\n        global losses\n        losses+=[loss]\n        print loss", 
            "execution_count": 6, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "class LossHistory(Callback):\n    def on_train_begin(self, logs={}):\n        self.losses = []\n\n    def on_batch_end(self, batch, logs={}):\n        self.losses.append(logs.get('loss'))\n        handleLoss(logs.get('loss'))", 
            "execution_count": 7, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "# design network\nmodel = None\n\ndef reloadModel():\n    global model\n    json_file = open('model.json', 'r')\n    loaded_model_json = json_file.read()\n    json_file.close()\n    model = model_from_json(loaded_model_json)\n    # load weights into new model\n    model.load_weights(\"model.h5\")\n    print(\"Loaded model from disk\")\n    model.compile(loss='mae', optimizer='adam')\n\nreloadModel()\n\ndef train(data):\n    data.shape = (300, 10, 3)\n    model.fit(data, data, epochs=15, batch_size=72, validation_data=(data, data), verbose=0, shuffle=False,callbacks=[LossHistory()])\n    data.shape = (3000, 3)\n\ndef score(data):\n    data.shape = (300, 10, 3)\n    yhat =  model.predict(data)\n    yhat.shape = (3000, 3)\n    return yhat", 
            "execution_count": 8, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "text": "Loaded model from disk\n", 
                    "output_type": "stream"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "# USA options = {\"org\": \"oqyrc5\", \"id\": \"anything\", \"auth-method\": \"apikey\", \"auth-key\": \"a-oqyrc5-gqjx6gmrpc\", \"auth-token\": \"XZmvYr0i7-@JoJotiB\"}\n# GER options = {\"org\": \"vpypwh\", \"id\": \"systemml\", \"auth-method\": \"apikey\", \"auth-key\": \"a-vpypwh-uo4xdahvcy\", \"auth-token\": \"BwEwDnKSzHEgr?IcEc\"}\noptions = {\"org\": \"vpypwh\", \"id\": \"systemml\", \"auth-method\": \"apikey\", \"auth-key\": \"a-vpypwh-uo4xdahvcy\", \"auth-token\": \"BwEwDnKSzHEgr?IcEc\"}\nclient = ibmiotf.application.Client(options)\nclient.connect()", 
            "execution_count": 9, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stderr", 
                    "text": "2017-12-14 07:54:18,776   ibmiotf.application.Client  INFO    Connected successfully: a:vpypwh:systemml\n", 
                    "output_type": "stream"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "q = Queue(7000)\nsimulator_status = 'disablesimulator'", 
            "execution_count": 10, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "def myEventCallback(event):\n    global simulator_status\n    if event.event == 'switch':\n        simulator_status = event.data[\"message\"]\n        client.publishEvent(\"0.16.2\", \"lorenz\", \"switch_confirm\", \"json\", simulator_status)\n    if event.event == 'osc':\n        sample = event.data\n        point = [sample[\"x\"], sample[\"y\"],sample[\"z\"]]\n        q.put(point)\n\nclient.deviceEventCallback = myEventCallback\nclient.subscribeToDeviceEvents(\"0.16.2\", \"lorenz\", \"switch\")\nclient.subscribeToDeviceEvents(\"0.16.2\", \"lorenz\", \"osc\")\nclient.publishEvent(\"0.16.2\", \"lorenz\", \"alert\", \"json\", {'message' : 'no alert'})", 
            "execution_count": 11, 
            "cell_type": "code", 
            "outputs": [
                {
                    "data": {
                        "text/plain": "True"
                    }, 
                    "metadata": {}, 
                    "execution_count": 11, 
                    "output_type": "execute_result"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "def doNN(data):\n    data_scaled = scaleData(data)\n    train(data_scaled)\n    yhat = score(data_scaled)\n    data_scaled.shape = (3000, 3)", 
            "execution_count": 12, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "#do_reset = False\n#reset_start = 0\n\ndef handleLoss(loss):\n    #global do_reset\n    #global reset_start\n    sys.stdout.write('*')\n    sys.stdout.flush()\n    myData={'loss' : str(loss)}\n    client.publishEvent(\"0.16.2\", \"lorenz\", \"status\", \"json\", myData)\n    if loss > 0.8:\n        print \"loss > 0.8\"\n        #do_reset = True\n        #reset_start = int(time.time())\n        client.publishEvent(\"0.16.2\", \"lorenz\", \"alert\", \"json\", {'message' : 'alert'})\n    #if do_reset:\n        #if reset_start + 15 < int(time.time()):\n            #print \"resetting\"\n            #client.publishEvent(\"0.16.2\", \"lorenz\", \"alert\", \"json\", {'message' : 'no alert'})\n            #reloadModel()\n            #do_reset = False\n            #reset_start = 0\n        ", 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }, 
        {
            "metadata": {}, 
            "source": "while True:\n    while not q.empty() and simulator_status=='disablesimulator':\n        if simulator_status == 'disablesimulator':\n            sys.stdout.write('.')\n            sys.stdout.flush()\n            point = q.get()\n            try:\n                data\n            except NameError:\n                data = np.array(point)\n            else:\n                data = np.append(data,point)\n            if data.size>=9000:\n                data = np.reshape(data,(3000,3))\n                print \"Sending window downstream to the neural network...\"\n                doNN(data)\n                print \"Training finished...\"\n                del data\n    if simulator_status == 'simulatehealthy':\n        reloadModel()\n        data_healthy = pickle.load(open('watsoniotp.healthy.phase_aligned.pickle', 'rb'))\n        data_healthy = data_healthy.reshape(3000,3)\n        print \"Sending healthy window downstream to the neural network...\"\n        doNN(data_healthy)\n        print \"Training finished...\"\n    if simulator_status == 'simulatebroken':\n        simulator_status = 'simulatehealthy'\n        client.publishEvent(\"0.16.2\", \"lorenz\", \"alert\", \"json\", {'message' : 'alert'})\n        data_broken = pickle.load(open('watsoniotp.broken.phase_aligned.pickle', 'rb'))\n        data_broken = data_broken.reshape(3000,3)\n        print \"Sending broken window downstream to the neural network...\"\n        doNN(data_broken)\n        print \"Training finished......\"\n        client.publishEvent(\"0.16.2\", \"lorenz\", \"alert\", \"json\", {'message' : 'no alert'})\n        client.publishEvent(\"0.16.2\", \"lorenz\", \"to_healthy\", \"json\", {'message' : 'healthy'})\n        reloadModel()\n            \n", 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": [
                {
                    "name": "stdout", 
                    "text": "Loaded model from disk\nSending healthy window downstream to the neural network...\n***************************************************************************Training finished...\nLoaded model from disk\nSending healthy window downstream to the neural network...\n***************************************************************************Training finished...\nLoaded model from disk\nSending healthy window downstream to the neural network...\n***************************************************************************Training finished...\nLoaded model from disk\nSending healthy window downstream to the neural network...\n***************************************************************************Training finished...\nLoaded model from disk\nSending healthy window downstream to the neural network...\n***************************************************************************Training finished...\nLoaded model from disk\nSending healthy window downstream to the neural network...\n***************************************************************************Training finished...\nLoaded model from disk\nSending healthy window downstream to the neural network...\n***************************************************************************Training finished...\nLoaded model from disk\nSending healthy window downstream to the neural network...\n***************************************************************************Training finished...\nLoaded model from disk\nSending healthy window downstream to the neural network...\n***************************************************************************Training finished...\nLoaded model from disk\nSending healthy window downstream to the neural network...\n***************************************************************************Training finished...\nLoaded model from disk\nSending healthy window downstream to the neural network...\n***************************************************************************Training finished...\nLoaded model from disk\nSending healthy window downstream to the neural network...\n***************************************************************************Training finished...\nLoaded model from disk\nSending healthy window downstream to the neural network...\n***************************************************************************Training finished...\nLoaded model from disk\nSending healthy window downstream to the neural network...\n***************************************************************************Training finished...\n", 
                    "output_type": "stream"
                }
            ]
        }, 
        {
            "metadata": {}, 
            "source": "", 
            "execution_count": null, 
            "cell_type": "code", 
            "outputs": []
        }
    ], 
    "nbformat": 4, 
    "metadata": {
        "kernelspec": {
            "name": "python2-spark21", 
            "language": "python", 
            "display_name": "Python 2 with Spark 2.1"
        }, 
        "language_info": {
            "version": "2.7.11", 
            "name": "python", 
            "pygments_lexer": "ipython2", 
            "mimetype": "text/x-python", 
            "codemirror_mode": {
                "name": "ipython", 
                "version": 2
            }, 
            "file_extension": ".py", 
            "nbconvert_exporter": "python"
        }
    }
}